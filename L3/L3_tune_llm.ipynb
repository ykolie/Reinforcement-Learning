{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1073ae28",
   "metadata": {},
   "source": [
    "# Step 3: Tune an LLM with RLHF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8bc26",
   "metadata": {},
   "source": [
    "#### Project environment setup\n",
    "\n",
    "The RLHF training process has been implemented in a machine learning pipeline as part of the (Google Cloud Pipeline Components) library. This can be run on any platform that supports KubeFlow Pipelines (an open source framework), and can also run on Google Cloud's Vertex AI Pipelines.\n",
    "\n",
    "To run it locally, install the following:\n",
    "\n",
    "```Python\n",
    "!pip3 install google-cloud-pipeline-components\n",
    "!pip3 install kfp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15e6900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-pipeline-components\n",
      "  Downloading google_cloud_pipeline_components-2.22.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 (from google-cloud-pipeline-components)\n",
      "  Downloading google_api_core-2.29.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting kfp<3.0.0,>=2.6.0 (from google-cloud-pipeline-components)\n",
      "  Downloading kfp-2.15.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-cloud-aiplatform<2,>=1.14.0 (from google-cloud-pipeline-components)\n",
      "  Downloading google_cloud_aiplatform-1.135.0-py2.py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=3.1.2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-cloud-pipeline-components) (3.1.6)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components)\n",
      "  Downloading protobuf-6.33.5-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components)\n",
      "  Downloading proto_plus-1.27.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components)\n",
      "  Downloading google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components) (2.32.5)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting cryptography>=38.0.3 (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components)\n",
      "  Downloading cryptography-46.0.4-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: packaging>=14.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components) (26.0)\n",
      "Collecting google-cloud-storage<4.0.0,>=2.10.0 (from google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading google_cloud_storage-3.8.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading google_cloud_bigquery-3.40.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading google_cloud_resource_manager-1.16.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting google-genai<2.0.0,>=1.59.0 (from google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading google_genai-1.60.0-py3-none-any.whl.metadata (53 kB)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: typing_extensions in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components) (4.15.0)\n",
      "Collecting docstring_parser<1 (from google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading grpcio-1.76.0-cp314-cp314-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading google_cloud_core-2.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading google_resumable_media-2.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage<4.0.0,>=2.10.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading google_crc32c-1.8.0-cp314-cp314-macosx_12_0_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components) (4.12.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components) (0.28.1)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading websockets-15.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting distro<2,>=1.7.0 (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components) (3.11)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from Jinja2<4,>=3.1.2->google-cloud-pipeline-components) (3.0.3)\n",
      "Collecting click>=8.1.8 (from kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click-option-group==0.5.7 (from kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components)\n",
      "  Downloading click_option_group-0.5.7-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting kfp-pipeline-spec<3,>=2.15.0 (from kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components)\n",
      "  Downloading kfp_pipeline_spec-2.15.2-py3-none-any.whl.metadata (433 bytes)\n",
      "Collecting kfp-server-api<3,>=2.15.0 (from kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components)\n",
      "  Downloading kfp_server_api-2.15.2.tar.gz (63 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kubernetes<31,>=8.0.0 (from kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components) (6.0.3)\n",
      "Collecting requests-toolbelt<2,>=0.8.0 (from kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tabulate<1,>=0.8.6 (from kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: urllib3<3.0.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components) (2.6.3)\n",
      "Requirement already satisfied: six>=1.10 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp-server-api<3,>=2.15.0->kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kubernetes<31,>=8.0.0->kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components) (1.9.0)\n",
      "Collecting requests-oauthlib (from kubernetes<31,>=8.0.0->kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes<31,>=8.0.0->kfp<3.0.0,>=2.6.0->google-cloud-pipeline-components)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading pydantic_core-2.41.5-cp314-cp314-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3->google-cloud-aiplatform<2,>=1.14.0->google-cloud-pipeline-components)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components) (3.4.4)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components)\n",
      "  Downloading pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-pipeline-components) (3.0)\n",
      "Downloading google_cloud_pipeline_components-2.22.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.29.0-py3-none-any.whl (173 kB)\n",
      "Downloading google_auth-2.48.0-py3-none-any.whl (236 kB)\n",
      "Downloading google_cloud_aiplatform-1.135.0-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading google_cloud_bigquery-3.40.0-py3-none-any.whl (261 kB)\n",
      "Downloading google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_resource_manager-1.16.0-py3-none-any.whl (400 kB)\n",
      "Downloading google_cloud_storage-3.8.0-py3-none-any.whl (312 kB)\n",
      "Downloading google_crc32c-1.8.0-cp314-cp314-macosx_12_0_x86_64.whl (30 kB)\n",
      "Downloading google_genai-1.60.0-py3-none-any.whl (719 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.4/719.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading google_resumable_media-2.8.0-py3-none-any.whl (81 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\n",
      "Downloading grpcio-1.76.0-cp314-cp314-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.76.0-py3-none-any.whl (14 kB)\n",
      "Downloading kfp-2.15.2-py3-none-any.whl (397 kB)\n",
      "Downloading click_option_group-0.5.7-py3-none-any.whl (11 kB)\n",
      "Downloading kfp_pipeline_spec-2.15.2-py3-none-any.whl (9.8 kB)\n",
      "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.27.0-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-6.33.5-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp314-cp314-macosx_10_12_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading websockets-15.0.1-py3-none-any.whl (169 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading cryptography-46.0.4-cp311-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: kfp-server-api\n",
      "  Building wheel for kfp-server-api (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-2.15.2-py3-none-any.whl size=114005 sha256=35be33f17eb7e6a30329de860488ec0493b6b199b93b7a3a0a32ba3df56f485d\n",
      "  Stored in directory: /Users/yolandaking/Library/Caches/pip/wheels/ea/80/39/816b6acdf44cf50d0ee907ad906d3ab3c14e7bd2228303a328\n",
      "Successfully built kfp-server-api\n",
      "Installing collected packages: websockets, typing-inspection, tenacity, tabulate, sniffio, pydantic-core, pyasn1, protobuf, oauthlib, grpcio, google-crc32c, docstring_parser, distro, click, annotated-types, rsa, requests-toolbelt, requests-oauthlib, pydantic, pyasn1-modules, proto-plus, kfp-server-api, kfp-pipeline-spec, googleapis-common-protos, google-resumable-media, cryptography, click-option-group, grpcio-status, google-auth, kubernetes, grpc-google-iam-v1, google-api-core, google-genai, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, kfp, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/40\u001b[0m [google-cloud-pipeline-components]mponents]orm]ager]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 click-8.3.1 click-option-group-0.5.7 cryptography-46.0.4 distro-1.9.0 docstring_parser-0.17.0 google-api-core-2.29.0 google-auth-2.48.0 google-cloud-aiplatform-1.135.0 google-cloud-bigquery-3.40.0 google-cloud-core-2.5.0 google-cloud-pipeline-components-2.22.0 google-cloud-resource-manager-1.16.0 google-cloud-storage-3.8.0 google-crc32c-1.8.0 google-genai-1.60.0 google-resumable-media-2.8.0 googleapis-common-protos-1.72.0 grpc-google-iam-v1-0.14.3 grpcio-1.76.0 grpcio-status-1.76.0 kfp-2.15.2 kfp-pipeline-spec-2.15.2 kfp-server-api-2.15.2 kubernetes-30.1.0 oauthlib-3.3.1 proto-plus-1.27.0 protobuf-6.33.5 pyasn1-0.6.2 pyasn1-modules-0.4.2 pydantic-2.12.5 pydantic-core-2.41.5 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rsa-4.9.1 sniffio-1.3.1 tabulate-0.9.0 tenacity-9.1.2 typing-inspection-0.4.2 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40df90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kfp in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.15.2)\n",
      "Requirement already satisfied: click>=8.1.8 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (8.3.1)\n",
      "Requirement already satisfied: click-option-group==0.5.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (0.5.7)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (0.17.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (2.29.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (2.48.0)\n",
      "Requirement already satisfied: google-cloud-storage<4,>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (3.8.0)\n",
      "Requirement already satisfied: kfp-pipeline-spec<3,>=2.15.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (2.15.2)\n",
      "Requirement already satisfied: kfp-server-api<3,>=2.15.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (2.15.2)\n",
      "Requirement already satisfied: kubernetes<31,>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (30.1.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=6.31.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (6.33.5)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (6.0.3)\n",
      "Requirement already satisfied: requests-toolbelt<2,>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (1.0.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (0.9.0)\n",
      "Requirement already satisfied: urllib3<3.0.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp) (2.6.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.72.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.27.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.32.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-auth<3,>=1.6.1->kfp) (0.4.2)\n",
      "Requirement already satisfied: cryptography>=38.0.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-auth<3,>=1.6.1->kfp) (46.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-auth<3,>=1.6.1->kfp) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-cloud-storage<4,>=2.2.1->kfp) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-cloud-storage<4,>=2.2.1->kfp) (2.8.0)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from google-cloud-storage<4,>=2.2.1->kfp) (1.8.0)\n",
      "Requirement already satisfied: six>=1.10 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp-server-api<3,>=2.15.0->kfp) (1.17.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp-server-api<3,>=2.15.0->kfp) (2026.1.4)\n",
      "Requirement already satisfied: python-dateutil in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kfp-server-api<3,>=2.15.0->kfp) (2.9.0.post0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kubernetes<31,>=8.0.0->kfp) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kubernetes<31,>=8.0.0->kfp) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from kubernetes<31,>=8.0.0->kfp) (3.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (3.11)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.1->kfp) (0.6.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from cryptography>=38.0.3->google-auth<3,>=1.6.1->kfp) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth<3,>=1.6.1->kfp) (3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c7818",
   "metadata": {},
   "source": [
    "### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8289be-0f03-4f97-aaf3-b4e80330bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import (RLFH is currently in preview)\n",
    "from google_cloud_pipeline_components.preview.llm \\\n",
    "import rlhf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ac4718-782d-4fe7-a39f-51fe5b423210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from KubeFlow pipelines\n",
    "from kfp import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef016774-5400-45be-9682-4b0b0daa9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a path to the yaml file\n",
    "RLHF_PIPELINE_PKG_PATH = \"rlhf_pipeline.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6abca02b-c43b-4301-8be0-a34949eb38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the compile function\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=rlhf_pipeline,\n",
    "    package_path=RLHF_PIPELINE_PKG_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3904e2b-593c-4c95-b0c8-f7334a1fa728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# PIPELINE DEFINITION\n",
      "# Name: rlhf-train-template\n",
      "# Description: Performs reinforcement learning from human feedback.\n",
      "# Inputs:\n",
      "#    accelerator_type: str [Default: 'GPU']\n",
      "#    deploy_model: bool [Default: True]\n",
      "#    encryption_spec_key_name: str [Default: '']\n",
      "#    eval_dataset: str\n",
      "#    instruction: str\n",
      "#    kl_coeff: float [Default: 0.1]\n"
     ]
    }
   ],
   "source": [
    "# Print the first lines of the YAML file\n",
    "!head rlhf_pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951da6e9",
   "metadata": {},
   "source": [
    "**Note**: to print the whole YAML file, use the following:\n",
    "```Python\n",
    "!cat rlhf_pipeline.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14851c",
   "metadata": {},
   "source": [
    "## Define the Vertex AI pipeline job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe574a96",
   "metadata": {},
   "source": [
    "### Define the location of the training and evaluation data\n",
    "Previously, the datasets were loaded from small JSONL files, but for typical training jobs, the datasets are much larger, and are usually stored in cloud storage (in this case, Google Cloud Storage).\n",
    "\n",
    "**Note:** Make sure that the three datasets are stored in the same Google Cloud Storage bucket.\n",
    "```Python\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/val/*.jsonl\",\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6410f32-475f-4fc6-a751-5fe627312085",
   "metadata": {},
   "source": [
    "### Choose the foundation model to be tuned\n",
    "\n",
    "In this case, we are tuning the [Llama-2](https://ai.meta.com/llama/) foundational model, the LLM to tune is called **large_model_reference**. \n",
    "\n",
    "We're tuning the llama-2-7b, but you can also run an RLHF pipeline on Vertex AI to tune models such as: the T5x or text-bison@001. \n",
    "\n",
    "```Python\n",
    "parameter_values={\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff91eb",
   "metadata": {},
   "source": [
    "### Calculate the number of reward model training steps\n",
    "\n",
    "**reward_model_train_steps** is the number of steps to use when training the reward model.  This depends on the size of your preference dataset. We recommend the model should train over the preference dataset for 20-30 epochs for best results.\n",
    "\n",
    "$$ stepsPerEpoch = \\left\\lceil \\frac{datasetSize}{batchSize} \\right\\rceil$$\n",
    "$$ trainSteps = stepsPerEpoch \\times numEpochs$$\n",
    "\n",
    "The RLHF pipeline parameters are asking for the number of training steps and not number of epochs. Here's an example of how to go from epochs to training steps, given that the batch size for this pipeline is fixed at 64 examples per batch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1031a7d-ed33-451b-aac4-1e1b616826c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preference dataset size\n",
    "PREF_DATASET_SIZE = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7cbe0db-19de-4b0b-bfd7-8bd06a22defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size is fixed at 64\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c94da3-3016-4743-baeb-50bedd330328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dfb58a8-9498-41b3-afc8-7ef81c4a7404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "REWARD_STEPS_PER_EPOCH = math.ceil(PREF_DATASET_SIZE / BATCH_SIZE)\n",
    "print(REWARD_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe291d6-6d5c-4fb8-a783-61fb21269766",
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f83ffdc9-29d6-40e7-be30-06693816de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of steps in the reward model training\n",
    "reward_model_train_steps = REWARD_STEPS_PER_EPOCH * REWARD_NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1f3df46-868f-470f-b4db-bbcd4ca6dfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410\n"
     ]
    }
   ],
   "source": [
    "print(reward_model_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e866f-828e-4d5b-9d42-d206b57cb0b9",
   "metadata": {},
   "source": [
    "### Calculate the number of reinforcement learning training steps\n",
    "The **reinforcement_learning_train_steps** parameter is the number of reinforcement learning steps to perform when tuning the base model. \n",
    "- The number of training steps depends on the size of your prompt dataset. Usually, this model should train over the prompt dataset for roughly 10-20 epochs.\n",
    "- Reward hacking: if given too many training steps, the policy model may figure out a way to exploit the reward and exhibit undesired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6880ae3-8977-4605-9b8d-e50013c03896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt dataset size\n",
    "PROMPT_DATASET_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08e1f705-9ff2-4204-b4f9-96bcaacf798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size is fixed at 64\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "898fd671-e3f1-4174-8c63-dd64af6baa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30281c30-3b29-4ec0-b7fc-0df4f0203349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "RL_STEPS_PER_EPOCH = math.ceil(PROMPT_DATASET_SIZE / BATCH_SIZE)\n",
    "print(RL_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3415a4c5-c816-46e1-8b1e-2b6b976f2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d16b09f-5e48-4c2e-bb33-0b719e0943fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of steps in the RL training\n",
    "reinforcement_learning_train_steps = RL_STEPS_PER_EPOCH * RL_NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b4079f9-0816-46c3-937f-3c85a491eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "print(reinforcement_learning_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b95cf-9f6f-45c2-810f-363f761a235b",
   "metadata": {},
   "source": [
    "### Define the instruction\n",
    "\n",
    "- Choose the task-specific instruction that you want to use to tune the foundational model.  For this example, the instruction is \"Summarize in less than 50 words.\"\n",
    "- You can choose different instructions, for example, \"Write a reply to the following question or comment.\" Note that you would also need to collect your preference dataset with the same instruction added to the prompt, so that both the responses and the human preferences are based on that instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14cbd66c-aeb2-4bf8-97f0-eba82e5de51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completed values for the dictionary\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/val/*.jsonl\",\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        \"reward_model_train_steps\": 1410,\n",
    "        \"reinforcement_learning_train_steps\": 320, # results from the calculations above\n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 1.0,\n",
    "        \"kl_coeff\": 0.1, # increased to reduce reward hacking\n",
    "        \"instruction\":\\\n",
    "    \"Summarize in less than 50 words\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c88a7",
   "metadata": {},
   "source": [
    "### Train with full dataset: dictionary 'parameter_values' \n",
    "\n",
    "- Adjust the settings for training with the full dataset to achieve optimal results in the evaluation. Take a look at the new values; these results are from various training experiments in the pipeline, and the best parameter values are displayed here.\n",
    "\n",
    "```python\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/reddit_tfds/val/*.jsonl\",\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        \"reward_model_train_steps\": 10000,\n",
    "        \"reinforcement_learning_train_steps\": 10000, \n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 0.2,\n",
    "        \"kl_coeff\": 0.1,\n",
    "        \"instruction\":\\\n",
    "    \"Summarize in less than 50 words\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc6d51",
   "metadata": {},
   "source": [
    "### Set up Google Cloud to run the Vertex AI pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9571014",
   "metadata": {},
   "source": [
    "If needed install Vertex AI SDK like this:\n",
    "```Python\n",
    "!pip3 install google-cloud-aiplatform\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a820b9b6-d93c-492c-8e0f-7570d4bc67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate in utils\n",
    "from utils import authenticate\n",
    "credentials, PROJECT_ID, STAGING_BUCKET = authenticate()\n",
    "\n",
    "# RLFH pipeline is available in this region\n",
    "REGION = \"europe-west4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf92aac",
   "metadata": {},
   "source": [
    "## Run the pipeline job on Vertex AI\n",
    "\n",
    "Now that we have created our dictionary of values, we can create a PipelineJob. This just means that the RLHF pipeline will execute on Vertex AI. So it's not running locally here in the notebook, but on some server on Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba1642b4-d16d-4e9b-ba87-3391168c5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "427dc778-9a04-4816-8569-0b5ea1c39f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project = PROJECT_ID,\n",
    "                location = REGION,\n",
    "                credentials = credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3eac3e3-2d17-47d7-b69f-97a20e91042b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rlhf_pipeline.yaml'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the path for the YAML file\n",
    "RLHF_PIPELINE_PKG_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa58dce",
   "metadata": {},
   "source": [
    "### Create and run the pipeline job\n",
    "- Here is how you would create the pipeline job and run it if you were working on your own project.\n",
    "- This job takes about a full day to run with multiple accelerators (TPUs/GPUs), and so we're not going to run it here due to that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3cf10",
   "metadata": {},
   "source": [
    "- To create the pipeline job:\n",
    "\n",
    "```Python\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"tutorial-rlhf-tuning\",\n",
    "    pipeline_root=STAGING_BUCKET,\n",
    "    template_path=RLHF_PIPELINE_PKG_PATH,\n",
    "    parameter_values=parameter_values)\n",
    "```\n",
    "- To run the pipeline job:\n",
    "\n",
    "```Python\n",
    "job.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bec5c2-7bc7-48f5-93e8-9bb9e5486000",
   "metadata": {},
   "source": [
    "- The content team has run this RLHF training pipeline to tune the Llama-2 model, next, you'll get to evaluate the log data to compare the performance of the tuned model with the original foundational model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
